{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNbzfGnz1eRe"
   },
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f2CKvrGF1jhD"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hX7iVExE1hAb"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# svm의 경우 soft 보팅이 실행 안됨 (확률예측 함수가 없음)\n",
    "voting = VotingClassifier(estimators=[(\"KNN\", knn), (\"LR\", lr)], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "GhF_0qhrGch5",
    "outputId": "cfb71882-e7f2-414c-bf0d-4c3857b5bb30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9370629370629371\n",
      "0.951048951048951\n",
      "0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "lr.fit(X_train, y_train)\n",
    "voting.fit(X_train, y_train)\n",
    "  \n",
    "pred_knn = knn.predict(X_test)\n",
    "pred_lr = lr.predict(X_test)\n",
    "pred_vote = voting.predict(X_test)\n",
    "\n",
    "print(accuracy_score(pred_knn, y_test))\n",
    "print(accuracy_score(pred_lr, y_test))\n",
    "print(accuracy_score(pred_vote, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqXToCsN1hQD"
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "My7aJ6Xz49-s"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "svc = SVC()\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "PnTWgAcF5xK0",
    "outputId": "0f6dfd7f-afe4-44c7-cb2a-f97338fea525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9370629370629371\n",
      "0.951048951048951\n",
      "0.9370629370629371\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "pred_knn = knn.predict(X_test)\n",
    "print(knn.score(X_test, y_test))\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "print(lr.score(X_test, y_test))\n",
    "svc.fit(X_train, y_train)\n",
    "pred_svc = svc.predict(X_test)\n",
    "print(svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "H4Xwh_Xi6mRV",
    "outputId": "0de9c13b-7e3f-41d7-ebcf-48941ab0d301"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143, 3), (143, 30))"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 모델을 합치기\n",
    "import numpy as np\n",
    "\n",
    "# transpose() : 전치 함수 -> X_test와 일치하도록 해야 함\n",
    "X_test_new = np.array([pred_knn, pred_lr, pred_svc]).transpose()\n",
    "X_test_new.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "4HhwQ0tn64Zs",
    "outputId": "04877d30-7c0f-4d8c-c580-1686116faa75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 최종 모델로 학습하기\n",
    "rf.fit(X_test_new, y_test)\n",
    "pred_rf = rf.predict(X_test_new)\n",
    "print(accuracy_score(pred_rf, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yK6WkLAmOllo"
   },
   "source": [
    "# Random  Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItTUCyMpgWEh"
   },
   "source": [
    "- 앙상블(ensemble)은 여러 머신러닝 모델을 연결하여 더 강력한 모델을 만드는 기법\n",
    "\n",
    "- 머신러닝에는 이런 종류의 모델이 많지만, 랜덤 포레스트random forest와 그래디언트 부스팅(gradient boosting) 결정 트리는 둘 다 모델을 구성하는 기본 요소로 결정 트리를 사용\n",
    "\n",
    "- 결정트리의 단점 : 과적합 문제\n",
    "\n",
    "- 랜던 포레스트 : 타킷 예측을 잘하고 구별되는 어러 개의 트리를 만들기 위해 무작위성을 부여\n",
    "\n",
    "- 랜덤 트리 생성 방법\n",
    "\n",
    "  (1) 트리를 만들 때 사용하는 데이터 포인트를 무작위로 선택하는 방법\n",
    "  \n",
    "  (2) 분할 테스트에서 특성을 무작위로 선택하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isHxndIZkI__"
   },
   "source": [
    "## 랜덤 포레스트 만들기\n",
    "- 랜덤 포레스트 모델을 만들려면 생성할 트리의 개수를 정해야 함 (RandomForestRegressor나 RandomForestClassifier의 n_estimators 매개변수)\n",
    "\n",
    "  ><b>(1) 트리를 만들기 위해 먼저 데이터의 부트스트랩 샘플bootstrap sample을 생성</b> (n_samples개의 데이터 포인트 중에서 무작위로 데이터를 n_samples 횟수만큼 반복 추출)\n",
    "\n",
    "- 부스스트랩 샘플의 예 ( [‘a’, ‘b’, ‘c’, ‘d’]에서 부트스트랩 샘플을 만든다고 하면)\n",
    "\n",
    "   [‘b’, ‘d’, ‘d’, ‘c’] ,  [‘d’, ‘a’, ‘d’, ‘a’], [‘a’, ‘a’, ‘c’, ‘b’] 등\n",
    "\n",
    "  ><b>(2) 생성한 데이터 셋으로 트리를 만듬</b>\n",
    "\n",
    "- 전체 데이터 셋 대상이 아닌 무작위로 선택한 데이터 셋 중에서 최선의 데이터 셋을 찾음\n",
    "- <font color=red>몇 개의 특성을 고를 지 선택 -> max_features</font>\n",
    "- <font color=red>몇 개의 트리를 만들 지 선택 -> n_estimators</font>\n",
    "-  max_features=1로 설정하면 트리의 분기는 테스트할 특성을 고를 필요가 없게 되며 무작위로 선택한 특성의 임계값을 찾기만 하면 됨\n",
    "\n",
    "- max_features 값을 크게 하면 랜덤 포레스트의 트리들은 매우 비슷해지고 가장 두드러진 특성을 이용해 데이터에 잘 맞춰질 것\n",
    "\n",
    "- max_features를 낮추면 랜덤 포레스트 트리들은 많이 달라지고 각 트리는 데이터에 맞추기 위해 깊이가 깊어지게 됨\n",
    "\n",
    "  ><b>(3) 모델에 있는 모든 트리의 예측을 만듬</b>\n",
    "-  회귀의 경우에는 이 예측들을 평균하여 최종 예측을 만듬\n",
    "- 분류의 경우는 약한 투표 전략을 사용 -> 각 알고리즘은 가능성 있는 출력 레이블의 확률을 제공함으로써 간접적인 예측하고 트리들이 예측한 확률을 평균내어 가장 높은 확률을 가진 클래스가 예측값이 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s26F4zVyqhCp"
   },
   "source": [
    "## 유방암 데이터를 이용한 학습\n",
    "\n",
    "- 유방암 데이터셋에 100개의 트리로 이뤄진 랜덤 포레스트를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yipg0i3l8d1k"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__5U7MtsOdWs",
    "outputId": "94c1700e-109b-45f3-bef6-46ff4eeab9a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 1.000\n",
      "테스트 세트 정확도: 0.979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=66)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAsWae4tq703"
   },
   "source": [
    "- 랜덤 포레스트는 아무런 매개변수 튜닝 없이도 선형 모델이나 단일 결정 트리보다 높은 97% 정확도를 냄\n",
    "\n",
    "- 단일 결정 트리에서 한 것처럼 max_features 매개변수를 조정하거나 사전 가지치기를 할 수도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82J7acy_bpr1"
   },
   "source": [
    "# AdaBoost (Adaptive Boosting)\n",
    "\n",
    "- GradientBoosting 처럼 약한 학습기를 사용\n",
    "- 다른 점은 이전의 모델이 잘못 분류한 샘플에 가중치를 높여서 다음 모델을 훈련시킴\n",
    "- 훈련된 각 모델은 성능에 따라 가중치가 부여됨\n",
    "- 예측을 만들 때는 모델이 예측된 레이블을 기준으로 모델의 가중치를 합산하여 가장 높은 값을 가진 레이블을 선택\n",
    "\n",
    "- GradientBoosting와 마찬가지로 순차적으로 학습해야 하므로 n_jobs 매개변수는 지원하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "YlQu0GzFcn4d",
    "outputId": "2cf3248e-a353-4b15-be8c-e53bfc3abd43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도 : 0.962\n",
      "테스트 세트 정확도 : 0.972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "bagging_adb = AdaBoostClassifier(n_estimators=5, random_state=42)\n",
    "bagging_adb.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도 : {:.3f}\".format(bagging_adb.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도 : {:.3f}\".format(bagging_adb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEPHVCZIdLt4"
   },
   "source": [
    "- AdaBoostCalssifier는 깊이가 1인 결정트리를 사용하므로 각 트리의 결정 경계가 직선 하나 뿐임.\n",
    "\n",
    "- 유방암 데이터를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "CNxMQaCqdb-J",
    "outputId": "e3872d4c-d3ec-411a-f60a-6c513cc5e4ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도 : 1.000\n",
      "테스트 세트 정확도 : 0.986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "bagging_adb2 = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "bagging_adb2.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도 : {:.3f}\".format(bagging_adb2.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도 : {:.3f}\".format(bagging_adb2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtDYsRHyGCk-"
   },
   "source": [
    "# GradientBoosting \n",
    "\n",
    "- 여러 개의 결정 트리를 묶어 강력한 모델을 만드는앙상블 방법\n",
    "\n",
    "- 회귀와 분류 모두에 사용\n",
    "\n",
    "- 랜덤 포레스트와는 달리 그래디언트 부스팅은 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 만듬 (무작위성이 없음)\n",
    "\n",
    "- 강력한 사전 가지치기가 사용\n",
    "\n",
    "- 보통 다섯 개 이하 깊이의 트리를 사용하므로 메모리를 적게 사용하고 예측도 빠름\n",
    "\n",
    "- 각각의 트리는 데이터의 일부에 대해서만 예측을 잘 수행할 수 있어서 트리가 많이 추가될수록 성능이 좋아짐\n",
    "\n",
    "-  랜덤 포레스트보다는 매개변수 설정에 조금 더 민감하지만 잘 조정하면 더 높은 정확도를 제공\n",
    "\n",
    "-  learning_rate : 이전 트리의 오차를 얼마나 강하게 보정할 것인지를 제어\n",
    "\n",
    "- 학습률이 크면 트리는 보정을 강하게 하기 때문에 복잡한 모델을 만듬\n",
    "\n",
    "- n_estimators 값을 키우면 앙상블에 트리가 더 많이 추가되어 모델의 복잡도가 커지고 훈련 세트에서의 실수를 바로잡을 기회가 더 많아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1gmdPTrH2lc"
   },
   "source": [
    "## 유방암 데이터 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "6bPWHczHOsL7",
    "outputId": "e99fcf87-bb77-4753-b8a9-994d8a9a5520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 1.000\n",
      "테스트 세트 정확도: 0.958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbrt1 = GradientBoostingClassifier(random_state=0)\n",
    "gbrt1.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(gbrt1.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(gbrt1.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JD5-rzmZIH_r"
   },
   "source": [
    "- 훈련 세트의 정확도가 100%이므로 과대적합\n",
    "- 과대적합을 막기 위해서 트리의 최대 깊이를 줄여 사전 가지치기를 강하게 하거나 학습률을 낮출 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "cjS7YY8IO1LH",
    "outputId": "ffafdb21-35ab-425d-865c-3df1edfec4a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.993\n",
      "테스트 세트 정확도: 0.979\n"
     ]
    }
   ],
   "source": [
    "gbrt2 = GradientBoostingClassifier(random_state=0, max_depth=1)\n",
    "gbrt2.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(gbrt2.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(gbrt2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1k9LPgA-IW6u"
   },
   "source": [
    "- 학습률을 조정한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "Krc0EbhSIUsh",
    "outputId": "b0972c13-7edf-4781-8000-3a3288c74e6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.984\n",
      "훈련 세트 정확도: 0.937\n"
     ]
    }
   ],
   "source": [
    "gbrt3 = GradientBoostingClassifier(random_state=0, learning_rate=0.01)\n",
    "gbrt3.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(gbrt3.score(X_train, y_train)))\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(gbrt3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tPyY4kvIfu9"
   },
   "source": [
    "- 두 방식은 모델의 복잡도를 감소시키므로 예상대로 훈련 세트의 정확도가 낮아짐\n",
    "- 학습률을 낮추는 것은 테스트 세트의 성능을 조금밖에 개선하지 못했지만, 트리의 최대 깊이를 낮추는 것은 모델 성능 향상에 크게 기여"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GR3M0JzqJ3uc"
   },
   "source": [
    "## 장단점\n",
    "\n",
    "- 지도 학습에서 가장 강력하고 널리 사용하는 모델 중 하나\n",
    "\n",
    "- 가장 큰 단점은 매개변수를 잘 조정해야 한다는 것과 훈련 시간이 길다는 것\n",
    "\n",
    "- 다른 트리 기반 모델처럼 특성의 스케일을 조정하지 않아도 되고 이진 특성이나 연속적인 특성에서도 잘 동작\n",
    "\n",
    "- 트리 기반 모델의 특성상 희소한 고차원 데이터에는 잘 작동하지 않음\n",
    "\n",
    "- 중요 매개변수 : 트리의 개수를 지정하는 <font color=red>n_estimators</font>, 이전 트리의 오차를 보정하는 정도를 조절하는 <font color=red>learning_rate</font>\n",
    "\n",
    "- 두 매개변수는 깊게 연관되며 learning_rate를 낮추면 비슷한 복잡도의 모델을 만들기 위해서 더 많은 트리를 추가해야 함\n",
    "\n",
    "- n_estimators가 클수록 좋은 랜덤 포레스트와는 달리 그래디언트 부스팅에서 n_estimators를 크게 하면 모델이 복잡해지고 과대적합될 가능성이 높아짐\n",
    "\n",
    "- 일반적인 관례는 가용한 시간과 메모리 한도에서 n_estimators를 맞추고 나서 적절한 learning_rate를 찾는 것\n",
    "\n",
    "- 중요한 또 다른 매개변수는 각 트리의 복잡도를 낮추는 <font color=red>max_depth</font>(또는 <font color=red>max_leaf_nodes</font>)\n",
    "\n",
    "- 일반적으로 그래디언트 부스팅 모델에서는 max_depth를 매우 작게 설정하며 트리의 깊이가 5보다 깊어지지 않게 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gHsge052edC"
   },
   "source": [
    "#Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "m7gb136M2hDR",
    "outputId": "5d58b205-134b-48ce-966a-5c4a9e7ea440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "_xhjVfBE2l15",
    "outputId": "79d7afee-ddd2-4add-a69f-822605e4eb40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.986\n",
      "훈련 세트 정확도: 0.965\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(random_state=0, max_depth=1)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(xgb.score(X_train, y_train)))\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(xgb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8KClVXVngjc"
   },
   "source": [
    "# Light GBM\n",
    "- XG Boosting에 비해 가볍고(Low memory) 빠르며 정확도가 높은 모델\n",
    "- Leaf-wise(수직방향, 비대칭)로 트리를 성장시킴(속도↑)\n",
    "   - Level-wise(수평방향, 깊이↓, 대칭)보다 오류가 더 적음(정확도↑) \n",
    "     \n",
    "- 대량(1만개 이상)의 데이터를 병렬로 빠르게 학습가능(Low Memory, GPU활용 가능)\n",
    "   → XG Boosting 대비 2~10배의 속도(동일 파라미터 설정 시)\n",
    "   → 소량의 데이터에서는 제대로 동작하지 않음(과대적합 위험)\n",
    "- 예측 속도가 빠름 (Leaf-wise 트리의 장점)\n",
    "   → 그러나 Level-wise에 비해 과적합에 민감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bgO__O6N2oBi",
    "outputId": "5a29a844-964c-41c7-9627-fc6e88002d94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Win0UJEqnfJ9"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# 트레이닝 데이터를 LightGBM에 맞는 데이터 세트 포맷으로 변환\n",
    "# LightGBM 트레이닝에 있어서 필수적\n",
    "# 모델의 정확도는 설정된 파라미터 값에 전적으로 달려 있음\n",
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "params = {}\n",
    "params['learning_rate'] = 0.003\n",
    "# rf (랜덤포레스트), dart, goss\n",
    "params['boosting_type'] = 'gbdt' \n",
    "# 이진분류 : 초기값은 회귀 분석 (regression (회귀), multiclass (다중 분류))\n",
    "params['objective'] = 'binary'\n",
    "# mae, mse, multi_logloss\n",
    "params['metric'] = 'binary_logloss'\n",
    "# 특성 비율\n",
    "params['sub_feature'] = 0.5\n",
    "# 2^max_depth보다 작아야 한다\n",
    "params['num_leaves'] = 10\n",
    "params['min_data'] = 50\n",
    "params['max_depth'] = 10\n",
    "\n",
    "# 훈련\n",
    "clf = lgb.train(params, d_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-oIiOPfngBD"
   },
   "outputs": [],
   "source": [
    "# 예측\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 이진 값으로 변환\n",
    "for i in range(0, y_pred.shape[0]):\n",
    "    if y_pred[i]>=.5:       \n",
    "        y_pred[i]=1\n",
    "    else:  \n",
    "        y_pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmnmPxUvplwj",
    "outputId": "6fbded2f-e962-4eb3-c3d7-ad6396f7c800"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8881118881118881"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zc3KeRPDrYUQ"
   },
   "source": [
    "- 더 빠른 속도 \n",
    "  - bagging_fraction\n",
    "  - max_bin은 작게\n",
    "  - save_binary 사용\n",
    "  - parallel learning 사용\n",
    "\n",
    "- 더 높은 정확도\n",
    "  - max_bin 크게\n",
    "  - num_iterations 크게, learing_rate 작게\n",
    "  - num_leaves 크게 (과적합 발생)\n",
    "  - boosting 알고리즘을 dart 사용\n",
    "- 과적합 줄이기\n",
    "  - max_bin 작게\n",
    "  - num_leaves 작게\n",
    "  - min_data_in_leaf와 min_sum_hessian_in_leaf 사용  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.0.6-cp37-none-win_amd64.whl (73.8 MB)\n",
      "Requirement already satisfied: pandas>=0.24.0 in d:\\anaconda3\\envs\\opencv\\lib\\site-packages (from catboost) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\egeg\\appdata\\roaming\\python\\python37\\site-packages (from catboost) (1.19.3)\n",
      "Requirement already satisfied: six in c:\\users\\egeg\\appdata\\roaming\\python\\python37\\site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\egeg\\appdata\\roaming\\python\\python37\\site-packages (from catboost) (1.4.1)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20-py3-none-any.whl (46 kB)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.9.0-py2.py3-none-any.whl (15.2 MB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\egeg\\appdata\\roaming\\python\\python37\\site-packages (from catboost) (3.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\anaconda3\\envs\\opencv\\lib\\site-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\anaconda3\\envs\\opencv\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in d:\\anaconda3\\envs\\opencv\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda3\\envs\\opencv\\lib\\site-packages (from matplotlib->catboost) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda3\\envs\\opencv\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anaconda3\\envs\\opencv\\lib\\site-packages (from matplotlib->catboost) (9.0.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in d:\\anaconda3\\envs\\opencv\\lib\\site-packages (from matplotlib->catboost) (2022.6.15)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda3\\envs\\opencv\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.3.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly, graphviz, catboost\n",
      "Successfully installed catboost-1.0.6 graphviz-0.20 plotly-5.9.0 tenacity-8.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.488306\n",
      "0:\tlearn: 0.2475590\ttotal: 138ms\tremaining: 1.24s\n",
      "1:\tlearn: 0.1339366\ttotal: 140ms\tremaining: 559ms\n",
      "2:\tlearn: 0.0827617\ttotal: 141ms\tremaining: 329ms\n",
      "3:\tlearn: 0.0645189\ttotal: 143ms\tremaining: 214ms\n",
      "4:\tlearn: 0.0476576\ttotal: 144ms\tremaining: 144ms\n",
      "5:\tlearn: 0.0382314\ttotal: 146ms\tremaining: 97.1ms\n",
      "6:\tlearn: 0.0309942\ttotal: 147ms\tremaining: 63.1ms\n",
      "7:\tlearn: 0.0245826\ttotal: 149ms\tremaining: 37.3ms\n",
      "8:\tlearn: 0.0212362\ttotal: 152ms\tremaining: 16.9ms\n",
      "9:\tlearn: 0.0180920\ttotal: 154ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x17c305897c8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catboost = CatBoostClassifier(iterations=10)\n",
    "\n",
    "catboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "y_pred = catboost.predict(X_test)\n",
    "\n",
    "# 이진 값으로 변환\n",
    "for i in range(0, y_pred.shape[0]):\n",
    "    if y_pred[i]>=.5:       \n",
    "        y_pred[i]=1\n",
    "    else:  \n",
    "        y_pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972027972027972"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0F4Q6MEBo7ZN"
   },
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "- 매개변수을 선택하는 것은 머신러닝에서 중요한 일\n",
    "\n",
    "- GridSearch : 관심 있는 매개변수들을 대상으로 가능한 모든 조합 시도하는 것\n",
    "- RandomSearch : 임의의 매개변수를 값들을 대상으로 조합을 시도하는 것\n",
    "- Bayesian Optimization : 임의의 매개변수를 값들을 대상으로 최적의 조합을 찾는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQhNYEqHaRcU"
   },
   "source": [
    "## GridSearch\n",
    "\n",
    "- GridSearch 기능과 교차검증을 동시에 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8alJXc2jaQvk"
   },
   "outputs": [],
   "source": [
    "# 딕셔너리 형태로 파라미터의 값들을 설정\n",
    "param_grid = {\"n_estimators\": range(1, 100, 5),\n",
    "              \"max_features\": range(1, 30, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Hk8otxS9ab0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_features': range(1, 30, 3),\n",
       "                         'n_estimators': range(1, 100, 5)})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# return_train_score : 훈련 폴드(cv)의 점수를 받을지 여부를 설정\n",
    "# scoring : 분류 (accuracy, f1), 회귀 (neg_mean_squared_error, r2)\n",
    "# n_jobs : 병렬처리 수 (CPU 코어 수가 충분하다면 설정, 디폴트 1) - 내부적으로 멀티프로세스 동작 -> 속도 증가\n",
    "#grid_search = GridSearchCV(SVC(), param_grid, cv=5, return_train_score=True, scoring='f1_micro', n_jobs=2)\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIAo7oxEatkV"
   },
   "source": [
    "- GridSearchCV 객체에 fit() 매서드는 최적의 매개변수를 찾는 일 뿐만 아니라 교차 검증 성능이 가장 좋은 매개변수로 전체 훈련 데이터 세트에 대해 새로운 모델을 자동을 만듬\n",
    "\n",
    "- GridSearchCV는 전체 데이터로 학습한 모델에 접근할 수 있도록 predict()와 score() 메서드 제공\n",
    "\n",
    "- GridSearchCV 분류 : StratifiedKFold 회귀 : KFold\n",
    "\n",
    "- 사용에 따라서는 predict_proba, decision_function도 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "E0Al46AxbOCc",
    "outputId": "07f0f770-41a5-445d-a485-12a1db37a0cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 세트 점수: 0.95\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 세트 점수: {:.2f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "VXVx0SyUbQzO",
    "outputId": "2cf2bd8e-7a3a-493e-c39d-0236664ec9a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 매개변수: {'max_features': 1, 'n_estimators': 86}\n",
      "최고 교차 검증 점수: 0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"최적 매개변수: {}\".format(grid_search.best_params_))\n",
    "print(\"최고 교차 검증 점수: {:.2f}\".format(grid_search.best_score_))\n",
    "print(\"최고 성능 모델:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3LXIYJNbV02"
   },
   "source": [
    "- 최적 매개 변수에서 전체 훈련 세트를 사용하여 학습한 모델은 best_estimator_\n",
    "\n",
    "- grid_search 객체가 predict와 score 메서드를 가지고 있으므로 예측이나 모델을 평가하기 위해 best_estimator_ 속성을 사용할 필요가 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'max_features': range(1, 30, 3),\n",
       "                                        'n_estimators': range(1, 100, 5)})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(), \n",
    "                                   param_grid, \n",
    "                                   random_state=0,\n",
    "                                   cv=5)\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 세트 점수: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 세트 점수: {:.2f}\".format(random_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 매개변수: {'n_estimators': 46, 'max_features': 10}\n",
      "최고 교차 검증 점수: 0.96\n",
      "최고 성능 모델:\n",
      "RandomForestClassifier(max_features=10, n_estimators=46)\n"
     ]
    }
   ],
   "source": [
    "print(\"최적 매개변수: {}\".format(random_search.best_params_))\n",
    "print(\"최고 교차 검증 점수: {:.2f}\".format(random_search.best_score_))\n",
    "print(\"최고 성능 모델:\\n{}\".format(random_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in d:\\anaconda3\\envs\\opencv\\lib\\site-packages (from scikit-optimize) (1.0.2)\n",
      "Collecting pyaml>=16.9\n",
      "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\egeg\\appdata\\roaming\\python\\python37\\site-packages (from scikit-optimize) (1.19.3)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\anaconda3\\envs\\opencv\\lib\\site-packages (from scikit-optimize) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\egeg\\appdata\\roaming\\python\\python37\\site-packages (from scikit-optimize) (1.4.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\egeg\\appdata\\roaming\\python\\python37\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda3\\envs\\opencv\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.2.0)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda3\\envs\\opencv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작값과 끝값을 설정\n",
    "param_grid = {\"n_estimators\": (1, 100),\n",
    "              \"max_features\": (1, 30)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=5, estimator=RandomForestClassifier(), random_state=0,\n",
       "              search_spaces={'max_features': (1, 30), 'n_estimators': (1, 100)})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "bayes_search = BayesSearchCV(RandomForestClassifier(), \n",
    "                             param_grid, \n",
    "                             random_state=0,\n",
    "                             cv=5)\n",
    "\n",
    "bayes_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 세트 점수: 0.94\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 세트 점수: {:.2f}\".format(bayes_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 매개변수: OrderedDict([('max_features', 1), ('n_estimators', 42)])\n",
      "최고 교차 검증 점수: 0.96\n",
      "최고 성능 모델:\n",
      "RandomForestClassifier(max_features=1, n_estimators=42)\n"
     ]
    }
   ],
   "source": [
    "print(\"최적 매개변수: {}\".format(bayes_search.best_params_))\n",
    "print(\"최고 교차 검증 점수: {:.2f}\".format(bayes_search.best_score_))\n",
    "print(\"최고 성능 모델:\\n{}\".format(bayes_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smVqT_pQ4QRa"
   },
   "source": [
    "# 특징 선택 (Feature Selection)\n",
    "\n",
    "- 특성의 수가 많아지면 모델이 복잡해지고 과대적합이 될 가능성이 높아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8SsC_wvTiqm"
   },
   "source": [
    "### 일변량 통계 \n",
    "\n",
    "- 특성과 라벨 사이의 통계적 관계를 분석하여 관계가 깊은 것만 선택\n",
    "\n",
    "- SelectKBest : 고정된 k개의 특성을 선택\n",
    "\n",
    "- SelectPercentile : 지정된 비율만큼 특성을 선택\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ar6-eC5NfMcR",
    "outputId": "b2fd5bbb-0a3b-4773-f5a0-efd1781fff9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=10, score_func=<function f_classif at 0x7f307c2f00d0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, SelectKBest, f_classif\n",
    "\n",
    "# SelectKBest의 k는 선택할 특성의 수를 지정\n",
    "select = SelectKBest(score_func=f_classif, k=10)\n",
    "select.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "bi6TgjqsilZJ",
    "outputId": "aed5276b-ad39-45b6-8b51-a4a5064d7e27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean perimeter', 'mean area', 'mean concavity',\n",
       "       'mean concave points', 'worst radius', 'worst perimeter',\n",
       "       'worst area', 'worst concavity', 'worst concave points'],\n",
       "      dtype='<U23')"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 선택한 특성 표시\n",
    "mask = select.get_support()\n",
    "cancer.feature_names[mask==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MtNw6ck5fW9j"
   },
   "outputs": [],
   "source": [
    "# 선택한 특성으로 된 데이터를 저장\n",
    "X_train_selected = select.transform(X_train)\n",
    "X_test_selected = select.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "--KDY1UGfi9q",
    "outputId": "53faa126-0728-4112-984b-fd5f1e186d7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 점수 (전체 특성): 0.923\n",
      "테스트 점수 (일부 선택): 0.909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=0.001)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"테스트 점수 (전체 특성): {:.3f}\".format(lr.score(X_test, y_test)))\n",
    "\n",
    "lr.fit(X_train_selected, y_train)\n",
    "print(\"테스트 점수 (일부 선택): {:.3f}\".format(lr.score(X_test_selected, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "cwZDWNQ_T7DW",
    "outputId": "31b87f54-be89-4a10-c65c-253be4097685"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectPercentile(percentile=50,\n",
       "                 score_func=<function f_classif at 0x7f307c2f00d0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f_classif(기본값)와 SelectPercentile을 사용하여 특성의 50%를 선택\n",
    "select = SelectPercentile(score_func=f_classif, percentile=50)\n",
    "select.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "M-54XjGwiJli",
    "outputId": "86778188-c354-4a40-ab4d-637b415ff271"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean perimeter', 'mean area', 'mean compactness',\n",
       "       'mean concavity', 'mean concave points', 'radius error',\n",
       "       'perimeter error', 'area error', 'worst radius', 'worst perimeter',\n",
       "       'worst area', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points'], dtype='<U23')"
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 선택한 특성 표시\n",
    "mask = select.get_support()\n",
    "cancer.feature_names[mask==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQBDiD3adMD_"
   },
   "outputs": [],
   "source": [
    "# 선택한 특성으로 된 데이터를 저장\n",
    "X_train_selected = select.transform(X_train)\n",
    "X_test_selected = select.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "ga1z-MDodGzy",
    "outputId": "728e927f-bd55-4b4a-a850-b3a2ca37d027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 점수 (전체 특성): 0.923\n",
      "테스트 점수 (일부 선택): 0.909\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=0.001)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"테스트 점수 (전체 특성): {:.3f}\".format(lr.score(X_test, y_test)))\n",
    "\n",
    "lr.fit(X_train_selected, y_train)\n",
    "print(\"테스트 점수 (일부 선택): {:.3f}\".format(lr.score(X_test_selected, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82zgI1yKfvbp"
   },
   "source": [
    "### 모델 기반 특성 선택\n",
    "\n",
    "- 지도 학습 모델로 계산된 중요도가 지정한 임계치보다 큰 모든 특성을 선택\n",
    "\n",
    "- 일변량 모델보다 훨씬 강력한 성능을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utDAHmxzf1eg"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 특성 선택 설정\n",
    "# threshold=\"median\" : 중간값을 임계치로 설정\n",
    "select = SelectFromModel(\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    threshold=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iK0uQ2Zrf9Dw"
   },
   "outputs": [],
   "source": [
    "# 특성 선택\n",
    "select.fit(X_train, y_train)\n",
    "X_train_selected = select.transform(X_train)\n",
    "X_test_selected = select.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "9onEd75LitTJ",
    "outputId": "fefc6751-23f3-416e-8f75-a84a0ffcaa6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean concavity', 'mean concave points', 'radius error',\n",
       "       'area error', 'worst radius', 'worst texture', 'worst perimeter',\n",
       "       'worst area', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points'], dtype='<U23')"
      ]
     },
     "execution_count": 120,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 선택한 특성 표시\n",
    "mask = select.get_support()\n",
    "cancer.feature_names[mask==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "4JRLbC2xg3TI",
    "outputId": "adeeeb28-5bec-41aa-bee9-8c69a4e0c036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 점수 (전체 특성): 0.923\n",
      "테스트 점수 (일부 선택): 0.909\n"
     ]
    }
   ],
   "source": [
    "# 모델에 적용\n",
    "lr = LogisticRegression(C=0.001)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"테스트 점수 (전체 특성): {:.3f}\".format(lr.score(X_test, y_test)))\n",
    "\n",
    "lr.fit(X_train_selected, y_train)\n",
    "print(\"테스트 점수 (일부 선택): {:.3f}\".format(lr.score(X_test_selected, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFhxa5N-hWaQ"
   },
   "source": [
    "### 반복적 특성 선택\n",
    "\n",
    "- 모든 특성으로 시작해서 반복적으로 특성 중요도가 낮은 특성을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaXfs_8BhbNw"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# n_features_to_select : 선택할 특성의 수\n",
    "select = RFE(RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "             n_features_to_select=10)\n",
    "\n",
    "select.fit(X_train, y_train)\n",
    "\n",
    "# 특성 선택\n",
    "X_train_selected = select.transform(X_train)\n",
    "X_test_selected = select.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "5y8YDK7Hi8SB",
    "outputId": "aee80fd2-f71c-4a21-fb64-e4cfe6bf7292"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean perimeter', 'mean area', 'mean concavity',\n",
       "       'mean concave points', 'area error', 'worst radius',\n",
       "       'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst concave points'], dtype='<U23')"
      ]
     },
     "execution_count": 123,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 선택한 특성 표시\n",
    "mask = select.get_support()\n",
    "cancer.feature_names[mask==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "mzTmRytPjImB",
    "outputId": "52feff2b-9dd5-4ebf-8764-e12a8da06c12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 점수 (전체 특성): 0.923\n",
      "테스트 점수 (일부 선택): 0.923\n"
     ]
    }
   ],
   "source": [
    "# 모델에 적용\n",
    "lr = LogisticRegression(C=0.001)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"테스트 점수 (전체 특성): {:.3f}\".format(lr.score(X_test, y_test)))\n",
    "\n",
    "lr.fit(X_train_selected, y_train)\n",
    "print(\"테스트 점수 (일부 선택): {:.3f}\".format(lr.score(X_test_selected, y_test)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "머신러닝복습_Ensemble_GridSearch_특성선택.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
